{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "import psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "access_key = 'Your-access-key'\n",
    "secret_key = 'Your-secret-key'\n",
    "vpc_id = 'Your default VPC Id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created security group with ID:  sg-03103c2cd4713cca3\n"
     ]
    }
   ],
   "source": [
    "#create security group by passing vpc_id and group name\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "#create security group\n",
    "ec2_client = boto3.client('ec2',\n",
    "                          region_name='us-east-2',\n",
    "                          aws_access_key_id = access_key,\n",
    "                          aws_secret_access_key=secret_key)\n",
    "\n",
    "group_name = 'my-redshift-security-group'\n",
    "group_description = 'Security group for redshift cluster access'\n",
    "\n",
    "try:\n",
    "    response = ec2_client.create_security_group(\n",
    "        GroupName=group_name,\n",
    "        Description=group_description,\n",
    "        VpcId=vpc_id\n",
    "    )\n",
    "    security_group_id = response['GroupId']\n",
    "    print('Created security group with ID: ', security_group_id)\n",
    "except ClientError as e:\n",
    "    if e.response['Error']['Code'] == 'InvalidGroup.Duplicate':\n",
    "        #The security group already exists\n",
    "        response = ec2_client.describe_security_groups(\n",
    "            Filters=[\n",
    "                {'Name':'group-name', 'Values':[group_name]},\n",
    "                {'Name':'vpc-id', 'Values':[vpc_id]}\n",
    "            ]\n",
    "        )\n",
    "        security_group_id = response['SecurityGroups'][0]['GroupId']\n",
    "        print('Security group already exists. Using existing security group with ID: ', security_group_id)\n",
    "    else:\n",
    "        #Handle other exceptions\n",
    "        print('Error creating security group:', e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inbound rule added to the security group.\n"
     ]
    }
   ],
   "source": [
    "#create inbound rule for security group\n",
    "\n",
    "port = 5439 #redshift port\n",
    "ip_range = '0.0.0.0/0'\n",
    "\n",
    "try:\n",
    "    # Add the inbound rule to the security group\n",
    "    response = ec2_client.authorize_security_group_ingress(\n",
    "        GroupId=security_group_id,\n",
    "        IpPermissions=[\n",
    "            {\n",
    "                # SSH ingress open to only the specified IP address.\n",
    "                \"IpProtocol\": \"tcp\",\n",
    "                \"FromPort\": port,\n",
    "                \"ToPort\": port,\n",
    "                \"IpRanges\": [{\"CidrIp\": ip_range}],\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "    print('Inbound rule added to the security group.')\n",
    "except ClientError as e:\n",
    "    if e.response['Error']['Code'] == 'InvalidPermission.Duplicate':\n",
    "        print('Inbound rule already exists for the specified port and IP range')\n",
    "    else:\n",
    "        print('Error adding the inbound rule', e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1 Creating a new IAM Role\n",
      "arn:aws:iam::339713044034:role/redshifttest\n"
     ]
    }
   ],
   "source": [
    "# Create the IAM role\n",
    "iam = boto3.client('iam',\n",
    "                       region_name='us-east-2',\n",
    "                       aws_access_key_id=access_key,\n",
    "                       aws_secret_access_key=secret_key)\n",
    "DWH_IAM_ROLE_NAME = 'redshifttest'\n",
    "try:\n",
    "    print('1.1 Creating a new IAM Role')\n",
    "    dwh_role = iam.create_role(\n",
    "    Path = '/',\n",
    "    RoleName = DWH_IAM_ROLE_NAME,\n",
    "    Description = 'Allows Redshift cluster to call AWS service on your behalf.',\n",
    "    AssumeRolePolicyDocument = json.dumps(\n",
    "        {'Statement': [{'Action': 'sts:AssumeRole',\n",
    "                    'Effect': 'Allow', \n",
    "                    'Principal': {'Service': 'redshift.amazonaws.com'}}],\n",
    "        'Version': '2012-10-17'})\n",
    "    )\n",
    "    # Attach Policy\n",
    "    iam.attach_role_policy(RoleName=DWH_IAM_ROLE_NAME,\n",
    "                            PolicyArn=\"arn:aws:iam::aws:policy/AmazonS3FullAccess\"\n",
    "                            )['ResponseMetadata']['HTTPStatusCode']\n",
    "    role_arn = iam.get_role(RoleName=DWH_IAM_ROLE_NAME)['Role']['Arn']\n",
    "    print(role_arn)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the cluster parameters used to create cluster in redshift\n",
    "cluster_parameters = {\n",
    "    #HW\n",
    "    'ClusterType':'single-node',\n",
    "    'NodeType':'dc2.large',\n",
    "    'NumberOfNodes':1,\n",
    "\n",
    "    #Identifiers & Credentials\n",
    "    'DBName':'mydatabase',\n",
    "    'ClusterIdentifier':'my-redshift-cluster',\n",
    "    'MasterUsername':'myawsuser',\n",
    "    'MasterUserPassword':'Password123',\n",
    "    'PubliclyAccessible': True,\n",
    "    \n",
    "    #Roles (for s3 access)\n",
    "    'IamRoles':[role_arn]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "redshift_client = boto3.client('redshift',\n",
    "                                region_name='us-east-2',\n",
    "                                aws_access_key_id=access_key,\n",
    "                                aws_secret_access_key=secret_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Redshift cluster creation intiated\n",
      "Redshift cluster is now available\n"
     ]
    }
   ],
   "source": [
    "# create the redshift cluster\n",
    "try:\n",
    "    response = redshift_client.create_cluster(**cluster_parameters)\n",
    "    print('Redshift cluster creation intiated')\n",
    "except redshift_client.exceptions.ClusterAlreadyExistsFault:\n",
    "    print('Cluster already exists. Skipping cluster creation')\n",
    "\n",
    "# wait for the cluster to be available\n",
    "redshift_client.get_waiter('cluster_available').wait(\n",
    "    ClusterIdentifier = cluster_parameters['ClusterIdentifier']\n",
    ")\n",
    "\n",
    "print('Redshift cluster is now available')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "product_table table created successfully or already exists.\n"
     ]
    }
   ],
   "source": [
    "# create a connnection to redshift using psycopg2\n",
    "redshift_endpoint = 'my-redshift-cluster.cfk74nwsnnkl.us-east-2.redshift.amazonaws.com'\n",
    "redshift_port = 5439\n",
    "redshift_user = 'myawsuser'\n",
    "redshift_password = 'Password123'\n",
    "redshift_database = 'mydatabase'\n",
    "redshift_table = 'product_table'\n",
    "\n",
    "conn = psycopg2.connect(host=redshift_endpoint,\n",
    "                        port=redshift_port,\n",
    "                        database=redshift_database,\n",
    "                        user=redshift_user,\n",
    "                        password=redshift_password)\n",
    "\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# create the table if it does not exist\n",
    "create_table_command = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS product_table(\n",
    "marketplace varchar(50),\n",
    "customer_id varchar(50),\n",
    "product_id varchar(50),\n",
    "seller_id varchar(50),\n",
    "sell_date varchar(50),\n",
    "quantity integer\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "    # Execute the create table command\n",
    "    cursor.execute(create_table_command)\n",
    "    conn.commit()\n",
    "    print('product_table table created successfully or already exists.')\n",
    "except psycopg2.Error as e:\n",
    "    print('Error creating table:', e)\n",
    "\n",
    "# Close the cursor and connection\n",
    "cursor.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Security Group Inbound Rules:\n",
      "{'FromPort': 5439, 'IpProtocol': 'tcp', 'IpRanges': [{'CidrIp': '0.0.0.0/0'}], 'Ipv6Ranges': [], 'PrefixListIds': [], 'ToPort': 5439, 'UserIdGroupPairs': []}\n"
     ]
    }
   ],
   "source": [
    "# Describe the security group\n",
    "security_group_id = 'sg-03103c2cd4713cca3'  # Replace with your actual security group ID\n",
    "\n",
    "try:\n",
    "    response = ec2_client.describe_security_groups(GroupIds=[security_group_id])\n",
    "    security_group = response['SecurityGroups'][0]\n",
    "    print('Security Group Inbound Rules:')\n",
    "    for rule in security_group['IpPermissions']:\n",
    "        print(rule)\n",
    "except ClientError as e:\n",
    "    print('Error describing security group:', e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COPY command executed successfully.\n"
     ]
    }
   ],
   "source": [
    "#Copy the data from s3 to redshift\n",
    "\n",
    "conn = psycopg2.connect(host=redshift_endpoint,\n",
    "                        port=redshift_port,\n",
    "                        database=redshift_database,\n",
    "                        user=redshift_user,\n",
    "                        password=redshift_password)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "\n",
    "\n",
    "copy_command = f\"\"\"\n",
    "COPY public.product_table\n",
    "FROM 's3://div-redshift-test/product_data.csv'\n",
    "CREDENTIALS 'aws_access_key_id={access_key};aws_secret_access_key={secret_key}'\n",
    "DELIMITER ',' IGNOREHEADER 1;\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "try:\n",
    "    # Execute the COPY command\n",
    "    cursor.execute(copy_command)\n",
    "    conn.commit()\n",
    "    print('COPY command executed successfully.')\n",
    "except psycopg2.Error as e:\n",
    "    print('Error executing COPY command:', e)\n",
    "\n",
    "# Close the cursor and connection\n",
    "cursor.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('US', '49033728', 'A6302503213', '1111', '31-08-2021', 10)\n",
      "('US', '17857748', 'B000059PET1', '2222', '20-09-2021', 20)\n",
      "('US', '25551507', 'S7888128071', '3333', '31-08-2021', 10)\n",
      "('US', '21025041', 'W630250993', '4444', '20-09-2021', 20)\n",
      "('US', '40943563', 'B00JENS2BI', '5555', '31-08-2021', 10)\n",
      "('US', '17013969', 'J6305761302', '6666', '05-09-2021', 30)\n",
      "('US', '47611685', 'K6300157555', '7777', '06-09-2021', 30)\n",
      "('US', '35680737', 'H6300189570', 'xxxx', '07-09-2021', 40)\n",
      "('US', '10747909', 'B000SXQ5US', 'yyyy', '08-09-2021', 20)\n"
     ]
    }
   ],
   "source": [
    "conn = psycopg2.connect(host=redshift_endpoint,\n",
    "                      port=redshift_port,\n",
    "                      database=redshift_database,\n",
    "                      user=redshift_user,\n",
    "                      password=redshift_password)\n",
    "\n",
    "# Create a cursor\n",
    "cur = conn.cursor()\n",
    "\n",
    "# Execute the SELECT query\n",
    "cur.execute(\"SELECT * FROM product_table\")\n",
    "\n",
    "# Fetch all the rows returned by the query\n",
    "rows = cur.fetchall()\n",
    "\n",
    "# Process the retrieved rows\n",
    "for row in rows:\n",
    "    print(row)\n",
    "\n",
    "# Close the cursor and connection\n",
    "cur.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drop table successfully.\n"
     ]
    }
   ],
   "source": [
    "# Connect to the Redshift cluster\n",
    "conn = psycopg2.connect(\n",
    "    host=redshift_endpoint,\n",
    "    port=redshift_port,\n",
    "    database=redshift_database,\n",
    "    user=redshift_user,\n",
    "    password=redshift_password\n",
    ")\n",
    "\n",
    "# Create a cursor\n",
    "cur = conn.cursor()\n",
    "\n",
    "# List of tables to drop\n",
    "tables_to_drop = ['product_table']\n",
    "\n",
    "# Drop the tables\n",
    "for table_name in tables_to_drop:\n",
    "    cur.execute(f\"DROP TABLE IF EXISTS {table_name}\")\n",
    "\n",
    "print('Drop table successfully.')    \n",
    "# Commit the changes to the database\n",
    "conn.commit()\n",
    "\n",
    "# Close the cursor and connection\n",
    "cur.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delete cluster successfully\n"
     ]
    }
   ],
   "source": [
    "cluster_identifier = 'my-redshift-cluster'\n",
    "\n",
    "redshift_client.delete_cluster(ClusterIdentifier=cluster_identifier,\n",
    "                               SkipFinalClusterSnapshot=True)\n",
    "\n",
    "redshift_client.get_waiter('cluster_deleted').wait(ClusterIdentifier=cluster_identifier)\n",
    "\n",
    "print(\"delete cluster successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': '2caf94b6-17a8-4b62-93c0-e585f4e6dfed',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '2caf94b6-17a8-4b62-93c0-e585f4e6dfed',\n",
       "   'cache-control': 'no-cache, no-store',\n",
       "   'strict-transport-security': 'max-age=31536000; includeSubDomains',\n",
       "   'content-type': 'text/xml;charset=UTF-8',\n",
       "   'content-length': '283',\n",
       "   'date': 'Fri, 07 Jun 2024 21:59:11 GMT',\n",
       "   'server': 'AmazonEC2'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Delete the security group\n",
    "ec2_client.delete_security_group(GroupId=security_group_id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
